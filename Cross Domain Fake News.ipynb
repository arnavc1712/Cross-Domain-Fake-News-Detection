{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, Dense,Embedding,RepeatVector,Bidirectional\n",
    "from keras.models import Model\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "# import demoji\n",
    "import tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = list(set(stopwords.words('english')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain1_path = \"./dEFEND/gossipcop_content_no_ignore.tsv\"\n",
    "domain2_path = \"./dEFEND/politifact_content_no_ignore.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain1_frame = pd.read_csv(domain1_path,delimiter=\"\\t\").set_index('id')\n",
    "domain2_frame = pd.read_csv(domain2_path,delimiter=\"\\t\").set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts for each label for the 2 domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gossipcop-9096198130</th>\n",
       "      <td>1</td>\n",
       "      <td>Sarah Jessica Parker is getting candid about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gossipcop-6982710185</th>\n",
       "      <td>1</td>\n",
       "      <td>Many celebrities have been sharing their thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gossipcop-7887456921</th>\n",
       "      <td>1</td>\n",
       "      <td>He reportedly hasn't seen her in over four yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gossipcop-1594778479</th>\n",
       "      <td>1</td>\n",
       "      <td>The fashion crowd is speaking out about Kim Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gossipcop-8172018375</th>\n",
       "      <td>1</td>\n",
       "      <td>What term do you want to search? Search with g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gossipcop-854842</th>\n",
       "      <td>0</td>\n",
       "      <td>Aisha Tyler‘s divorce from Jeffrey Tietjens ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gossipcop-843491</th>\n",
       "      <td>0</td>\n",
       "      <td>All four of Queen Elizabeth and Prince Philip'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gossipcop-897778</th>\n",
       "      <td>0</td>\n",
       "      <td>Theresa Caputo is adjusting to her new life af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gossipcop-899849</th>\n",
       "      <td>0</td>\n",
       "      <td>Follow Us on Twitter  Nominations for the 25th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gossipcop-927093</th>\n",
       "      <td>0</td>\n",
       "      <td>Though the happy couple can’t be together in p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label                                            content\n",
       "id                                                                            \n",
       "gossipcop-9096198130      1  Sarah Jessica Parker is getting candid about h...\n",
       "gossipcop-6982710185      1  Many celebrities have been sharing their thoug...\n",
       "gossipcop-7887456921      1  He reportedly hasn't seen her in over four yea...\n",
       "gossipcop-1594778479      1  The fashion crowd is speaking out about Kim Ka...\n",
       "gossipcop-8172018375      1  What term do you want to search? Search with g...\n",
       "...                     ...                                                ...\n",
       "gossipcop-854842          0  Aisha Tyler‘s divorce from Jeffrey Tietjens ha...\n",
       "gossipcop-843491          0  All four of Queen Elizabeth and Prince Philip'...\n",
       "gossipcop-897778          0  Theresa Caputo is adjusting to her new life af...\n",
       "gossipcop-899849          0  Follow Us on Twitter  Nominations for the 25th...\n",
       "gossipcop-927093          0  Though the happy couple can’t be together in p...\n",
       "\n",
       "[5816 rows x 2 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain1_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "label       \n",
       "0       3586\n",
       "1       2230"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain1_frame.groupby(['label'])[['label']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "label       \n",
       "0        145\n",
       "1        270"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain2_frame.groupby(['label'])[['label']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[()\\\"_#/@;*%:{}<>`+=~|.!?,'$-\\[\\]]\", \"\", text)\n",
    "    text = re.sub(r\"[0-9]\", \"\", text)\n",
    "    \n",
    "#     for words in stopwords_list:\n",
    "#         text = re.sub(r\"\\b{}\\b\".format(words),\"\",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagger(decoder_input_sentence):\n",
    "    start = \"<BOS> \"\n",
    "    end = \" <EOS>\"\n",
    "    final_target = [start + text + end for text in decoder_input_sentence] \n",
    "    return final_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenizer(text_lists):\n",
    "#     return [line.split(\" \") for line in text_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(text_lists):\n",
    "    tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
    "    tokenizer.fit_on_texts(text_lists)\n",
    "    \n",
    "    dictionary = tokenizer.word_index\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    for k,v in dictionary.items():\n",
    "        word2idx[k]=v\n",
    "        idx2word[v]=k\n",
    "    \n",
    "    return word2idx,idx2word,tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = domain1_frame['content'].apply(lambda x: clean_text(x)).values.tolist()+ domain2_frame['content'].apply(lambda x: clean_text(x)).values.tolist()\n",
    "# encoder_inputs = \n",
    "decoder_inputs = tagger(encoder_inputs[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx,idx2word,tokenizer = create_vocab(encoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to ambiguity with regards to Keras Tokenizer num_words, below is a good enough fix, though it changes the tokenizer word_index outside of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 30000\n",
    "\n",
    "sorted_by_word_count = sorted(tokenizer.word_counts.items(), key=lambda kv: kv[1], reverse=True)\n",
    "tokenizer.word_index = {}\n",
    "word2idx = {}\n",
    "idx2word = {}\n",
    "i = 0\n",
    "for word,count in sorted_by_word_count:\n",
    "    if i == num_words:\n",
    "        break\n",
    "\n",
    "    tokenizer.word_index[word] = i + 1    # <= because tokenizer is 1 indexed\n",
    "    word2idx[word] = i+1\n",
    "    idx2word[i+1]=word\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index[tokenizer.oov_token] = num_words+1\n",
    "word2idx[tokenizer.oov_token] = num_words+1\n",
    "idx2word[num_words+1]=tokenizer.oov_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = len(tokenizer.word_index)+1\n",
    "# tokenizer.word_index[\"<BOS>\"] = idx\n",
    "# word2idx[\"<BOS>\"] = idx\n",
    "# idx2word[idx] = \"<BOS>\"\n",
    "\n",
    "# idx = len(tokenizer.word_index)+1\n",
    "# tokenizer.word_index[\"<EOS>\"] = idx\n",
    "# word2idx[\"<EOS>\"] = idx\n",
    "# idx2word[idx] = \"<EOS>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30001"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[\"<UNK>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_encoder_inputs = tokenizer.texts_to_sequences(encoder_inputs)\n",
    "t_decoder_inputs = tokenizer.texts_to_sequences(decoder_inputs)\n",
    "\n",
    "\n",
    "# \n",
    "t_encoder_inputs = pad_sequences(t_encoder_inputs,maxlen=10,padding='post', truncating='post')\n",
    "\n",
    "# t_decoder_inputs = pad_sequences(t_encoder_inputs,maxlen=100,padding='post', truncating='post')\n",
    "# t_decoder_inputs = np.insert(t_decoder_inputs,0,word2idx[\"<BOS>\"],axis=1)\n",
    "# t_decoder_inputs = np.insert(t_decoder_inputs,t_decoder_inputs.shape[1],word2idx[\"<EOS>\"],axis=1)\n",
    "\n",
    "\n",
    "max_encoder_len = max([len(val) for val in t_encoder_inputs])\n",
    "max_decoder_len = max([len(val) for val in t_decoder_inputs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(X,Y,batch_size=128,max_len=5):\n",
    "    \n",
    "        \n",
    "    \n",
    "    for idx in range(0,len(X),batch_size):\n",
    "\n",
    "        encoder_input = np.zeros((batch_size,max_encoder_len))\n",
    "#         decoder_input = np.zeros((batch_size,max_decoder_len))\n",
    "        decoder_target = np.zeros((batch_size,max_encoder_len,len(word2idx)+1))\n",
    "        for j,input_seq in enumerate(X[idx:idx+batch_size]):\n",
    "            for i,word_idx in enumerate(input_seq):\n",
    "                encoder_input[j,i]= word_idx\n",
    "                decoder_target[j,i,word_idx] = 1\n",
    "           \n",
    "        yield [encoder_input,decoder_target]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data_generator(X,Y):\n",
    "    encoder_input = np.zeros((len(X),max_encoder_len))\n",
    "    decoder_input = np.zeros((len(X),max_decoder_len))\n",
    "    decoder_target = np.zeros((len(X),max_encoder_len,len(word2idx)+1)) ## Extra index for padding, word2idx is 1 indexed\n",
    "    for j,(input_seq,target_seq) in enumerate(zip(X,Y)):\n",
    "        for i,word_idx in enumerate(input_seq):\n",
    "            encoder_input[j,i]= word_idx\n",
    "            decoder_target[j,i,word_idx] = 1\n",
    "\n",
    "\n",
    "    return [encoder_input,decoder_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = test_generator(t_encoder_inputs,t_encoder_inputs,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len= len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_enc,test_dec = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 952., 1064., 2305.,    8.,  269., 4031.,   35.,   13.,  136.,\n",
       "         12.])"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_enc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Glove Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-388-49e19d755530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0membeddings_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/University_Stuff/SMM/Cross-Domain-Fake-News-Detection/venv/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_len+1, 100))\n",
    "for word, i in word2idx.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i+1] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30002, 100)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(max_encoder_len,),name=\"encoder_inputs\")\n",
    "\n",
    "encoder_embedding = Embedding(vocab_len+1,150,trainable=True,input_length=max_encoder_len,mask_zero=False,name=\"encoder_embedding\")\n",
    "\n",
    "encoder_inputs = encoder_embedding(inputs)\n",
    "\n",
    "# encoder_inputs = LSTM(64,return_sequences=True)(encoder_inputs)\n",
    "encoder = LSTM(64,return_state=True)\n",
    "\n",
    "# encoder = Bidirectional(LSTM(64, \n",
    "#                     return_state=True, \n",
    "#                     name = 'encoder'))\n",
    "\n",
    "# encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# # We discard `encoder_outputs` and only keep the states.\n",
    "\n",
    "# encoder_states = [forward_h, backward_h]\n",
    "encoder_states = [state_h,state_c]\n",
    "\n",
    "# # Set up the decoder, using `encoder_states` as initial state.\n",
    "\n",
    "\n",
    "\n",
    "decoder_inputs = RepeatVector(max_encoder_len)(encoder_outputs)\n",
    "\n",
    "# # We set up our decoder to return full output sequences,\n",
    "# # and to return internal states as well. We don't use the\n",
    "# # return states in the training model, but we will use them in inference.\n",
    "\n",
    "decoder_lstm = LSTM(64, \n",
    "                         return_state=True,\n",
    "                        return_sequences=True,\n",
    "                         name = 'decoder_lstm')\n",
    "\n",
    "\n",
    "# # The inital_state call argument, specifying the initial state(s) of a RNN. \n",
    "# # This is used to pass the encoder states to the decoder as initial states.\n",
    "# # Basically making the first memory of the decoder the encoded semantics\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "# decoder_outputs = LSTM(128,return_sequences=True)(decoder_outputs)\n",
    "\n",
    "# decoder_outputs = Dense(64,activation=\"tanh\")(decoder_outputs)\n",
    "decoder_dense = Dense(vocab_len+1, \n",
    "                      activation='softmax', \n",
    "                      name = 'decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# # Define the model that will turn\n",
    "# # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model(inputs,decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, 10, 150)      4500300     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm_21 (LSTM)                  [(None, 64), (None,  55040       encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_21 (RepeatVector) (None, 10, 64)       0           lstm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, 10, 64), (No 33024       repeat_vector_21[0][0]           \n",
      "                                                                 lstm_21[0][1]                    \n",
      "                                                                 lstm_21[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, 10, 30002)    1950130     decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,538,494\n",
      "Trainable params: 6,538,494\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = test_generator(t_encoder_inputs,t_decoder_inputs,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [encoder_input_data,decoder_input_data],decoder_target_data = next(generator)\n",
    "encoder_input_data,decoder_target_data = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data,decoder_target_data = all_data_generator(t_encoder_inputs,t_decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 10)"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  61.,  248.,  198., 2020., 9961.,   43.,   15., 1232.,   19.,\n",
       "        848.])"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [encoder_input_data,decoder_input_data],decoder_target_data = all_data_generator(t_encoder_inputs,t_decoder_inputs)\n",
    "# encoder_input_data,decoder_target_data = all_data_generator(t_encoder_inputs,t_decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 952., 1064., 2305.,    8.,  269., 4031.,   35.,   13.,  136.,\n",
       "         12.])"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnav1712/Desktop/University_Stuff/SMM/Cross-Domain-Fake-News-Detection/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 10.3070\n",
      "Epoch 2/40\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 10.2923\n",
      "Epoch 3/40\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 10.2194\n",
      "Epoch 4/40\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 9.8061\n",
      "Epoch 5/40\n",
      "256/256 [==============================] - 4s 16ms/step - loss: 9.1049\n",
      "Epoch 6/40\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 8.5505\n",
      "Epoch 7/40\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 8.1496\n",
      "Epoch 8/40\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 7.8484\n",
      "Epoch 9/40\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 7.6136\n",
      "Epoch 10/40\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 7.4246\n",
      "Epoch 11/40\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 7.2700\n",
      "Epoch 12/40\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 7.1399\n",
      "Epoch 13/40\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 7.0287\n",
      "Epoch 14/40\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 6.9342\n",
      "Epoch 15/40\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 6.8504\n",
      "Epoch 16/40\n",
      "256/256 [==============================] - 4s 17ms/step - loss: 6.7761\n",
      "Epoch 17/40\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 6.7127\n",
      "Epoch 18/40\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 6.6555\n",
      "Epoch 19/40\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 6.6030\n",
      "Epoch 20/40\n",
      "128/256 [==============>...............] - ETA: 2s - loss: 6.5588"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "history = model.fit(encoder_input_data, \n",
    "                    decoder_target_data,\n",
    "                    batch_size=128,\n",
    "                    epochs=40)\n",
    "#                     validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jennifer lawrence margot robbie more teach drinking <UNK> from around "
     ]
    }
   ],
   "source": [
    "for idx in encoder_input_data[0]:\n",
    "    print(idx2word[idx],end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict([encoder_input_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> "
     ]
    }
   ],
   "source": [
    "for idx in output_array[1]:\n",
    "    lookup = np.argmax(idx)\n",
    "#     print(lookup)\n",
    "    if lookup==0:\n",
    "        break\n",
    "    else:\n",
    "        print(idx2word[lookup],end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00092815526\n"
     ]
    }
   ],
   "source": [
    "for idx in output_array[100]:\n",
    "    print(idx[np.argmax(20)])\n",
    "    break\n",
    "    lookup = np.argmax(idx)\n",
    "#     print(lookup)\n",
    "    if lookup==0:\n",
    "        break\n",
    "    else:\n",
    "        print(idx2word[lookup],end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Social",
   "language": "python",
   "name": "social"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
